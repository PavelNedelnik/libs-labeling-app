{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.layers import Conv1D, Reshape, GlobalAveragePooling2D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constants import *\n",
    "\n",
    "NUM_CLASSES = 3\n",
    "DIM = (70, 70) # allways needs to be set to the dimension of the dataset!\n",
    "app_mode = 0 # 0 - toy dataset, 1 - evaluation on real dataset, 2 - evaluation on synthetic data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from src.simulation import generate_map\n",
    "\n",
    "if app_mode == 0:\n",
    "    calibration = np.load(open('data/calibration.npy', 'rb'))  # wavelengths\n",
    "    X = np.load(open('data/X.npy', 'rb'))  # measured data, dimensions are (index of measurement, wavelength)\n",
    "\n",
    "    # make hyperspectral map\n",
    "    X.resize(DIM + (calibration.shape[0],))\n",
    "    # input data has snake index\n",
    "    X[::2, :] = X[::2, ::-1]\n",
    "\n",
    "elif app_mode == 1:\n",
    "    calibration = np.load(open('data/X2_wavelengths.npy', 'rb'))  # wavelengths\n",
    "    X = np.load(open('data/X2.npy', 'rb'))  # measured data, dimensions are (index of measurement, wavelength)\n",
    "\n",
    "    X.resize(DIM + (calibration.shape[0],))\n",
    "    X[::2, :] = X[::2, ::-1]\n",
    "    \n",
    "    y_true = np.load(open('data/y2.npy', 'rb'))\n",
    "\n",
    "else:\n",
    "    seed = np.array(json.load(open('simulated_data/seed.json', 'r')))\n",
    "    X, y_true, calibration = generate_map(\n",
    "        50,\n",
    "        ['Fe', 'C', 'Cr', 'Ni', 'Mn'],\n",
    "        seed, np.random.uniform(0, 2, 50),\n",
    "        noise_var=1e-3,\n",
    "        noise_mean=0,\n",
    "        boundary_size=1,\n",
    "        smooth_kernel=np.ones((1,)),\n",
    "        cache=True\n",
    "    )\n",
    "\n",
    "# cache the actual input to the models\n",
    "X_in = X.reshape((-1, calibration.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SHAPE = X_in.shape[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class IWrapper(ABC):\n",
    "    @abstractmethod\n",
    "    def fit(self, X, y):\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, X):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicWrapper(IWrapper):\n",
    "    def __init__(self, model, bool_function) -> None:\n",
    "        self.model = model\n",
    "        self.predicate = bool_function\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        xy_data = zip(X, y)\n",
    "        X_, y_ = zip(*filter(self.predicate, xy_data))\n",
    "\n",
    "        (self.model).fit(X_, y_)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class PCAWrapper(IWrapper):\n",
    "    def __init__(self, model, bool_function) -> None:\n",
    "        self.model = model\n",
    "        self.predicate = bool_function\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.pca = PCA(n_components=128)\n",
    "        tmp_x = self.pca.fit_transform(X)\n",
    "\n",
    "        xy_data = zip(tmp_x, y)\n",
    "        X_, y_ = zip(*filter(self.predicate, xy_data))\n",
    "\n",
    "        self.model.fit(X_, y_)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        tmp = self.pca.transform(X)\n",
    "\n",
    "        return self.model.predict(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasWrapper(IWrapper):\n",
    "    def __init__(self, model: Sequential, bool_function) -> None:\n",
    "        self.model = model\n",
    "        self.predicate = bool_function\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        xy_data = zip(X, y)\n",
    "        X_, y_ = zip(*filter(self.predicate, xy_data))\n",
    "        \n",
    "        # To figure out that this retype is necessary only took 3 hours of debugging\n",
    "        X_ = np.array(X_)\n",
    "        y_ = np.array(y_)\n",
    "\n",
    "        tmp_y = to_categorical(y_, num_classes=NUM_CLASSES)\n",
    "\n",
    "        (self.model).fit(X_, tmp_y, epochs=10)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.model.predict(X), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferKerasWrapper(IWrapper):\n",
    "    def __init__(self, model: Sequential, bool_function, shape) -> None:\n",
    "        self.model = model\n",
    "        self.predicate = bool_function\n",
    "        self.shape = shape\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        xy_data = zip(X, y)\n",
    "        X_, y_ = zip(*filter(self.predicate, xy_data))\n",
    "        \n",
    "        # To figure out that this retype is necessary only took 3 hours of debugging\n",
    "        X_ = np.array(X_)#.reshape((len(y_),*self.shape))\n",
    "        y_ = np.array(y_)\n",
    "\n",
    "        tmp_y = to_categorical(y_, num_classes=NUM_CLASSES)\n",
    "\n",
    "        (self.model).fit(X_, tmp_y, epochs=1)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        tmp = np.array(X)#.reshape((len(X),*self.shape))\n",
    "        return np.argmax(self.model.predict(tmp), axis=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Add Keras NN\n",
    "model_keras_nn = Sequential()\n",
    "model_keras_nn.add(Dense(1024, input_shape=(DATA_SHAPE,), activation=\"relu\"))\n",
    "model_keras_nn.add(Dropout(0.2))\n",
    "model_keras_nn.add(Dense(512, activation=\"relu\"))\n",
    "model_keras_nn.add(Dropout(0.2))\n",
    "model_keras_nn.add(Dense(256, activation=\"relu\"))\n",
    "model_keras_nn.add(Dense(NUM_CLASSES, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras_nn.compile(optimizer = 'adam' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transfer learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also tried looking at the code from this paper if it is any better (so we don't have to encode it as a 2D image):\n",
    "\n",
    "https://github.com/NUST-Machine-Intelligence-Laboratory/hsi_road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model = ResNet50V2(weights='imagenet', input_shape=input_shape, include_top = False)\n",
    "base_model = MobileNetV2(weights='imagenet', input_shape=(62, 62, 3), include_top = False)\n",
    "base_model.trainable = False\n",
    "\n",
    "# needs to be transformed to image since the model expects images\n",
    "# 88 * 44 equals 3872 - the length of spectra\n",
    "# inputs = keras.Input(shape=(3872, 1, 1))\n",
    "transfer_model = Sequential()\n",
    "transfer_model.add(Conv1D(filters=3, kernel_size=29, activation='relu', input_shape=(3872,1)))\n",
    "transfer_model.add(Reshape((62, 62, 3)))\n",
    "transfer_model.add(base_model)\n",
    "transfer_model.add(GlobalAveragePooling2D())\n",
    "transfer_model.add(Dense(NUM_CLASSES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.compile(optimizer = 'adam' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.random.randint(low=0, high=4, size=4900)\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfer_model.fit(X_in, labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(3872,1)))\n",
    "cnn_model.add(MaxPooling1D(2))\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(2))\n",
    "cnn_model.add(Conv1D(256, 3, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(128, activation='relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer = 'adam' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn_model.fit(X_in, labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering_predicate = lambda x: x[1] >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# TODO - add MLP\n",
    "models = [KMeans(n_clusters=NUM_CLASSES, n_init='auto'),\n",
    "          BasicWrapper(GaussianNB(), filtering_predicate),\n",
    "          BasicWrapper(KNeighborsClassifier(n_jobs=-1), filtering_predicate),\n",
    "          BasicWrapper(RandomForestClassifier(max_depth=3), filtering_predicate),\n",
    "          BasicWrapper(GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0), filtering_predicate),\n",
    "          BasicWrapper(MLPClassifier(hidden_layer_sizes=(150, 100, 50), max_iter=300, activation='relu', solver='adam', random_state=1), filtering_predicate),\n",
    "          BasicWrapper(MLPClassifier(hidden_layer_sizes=(256, 128, 64, 32), max_iter=300, activation='relu', solver='adam', random_state=1), filtering_predicate),\n",
    "          PCAWrapper(SVC(random_state=0), filtering_predicate),\n",
    "          PCAWrapper(MLPClassifier(hidden_layer_sizes=(256, 128, 64, 32), max_iter=300, activation='relu', solver='adam', random_state=1), filtering_predicate),\n",
    "          KerasWrapper(model_keras_nn, filtering_predicate),\n",
    "          TransferKerasWrapper(transfer_model, filtering_predicate, (88,44,1)),\n",
    "          KerasWrapper(cnn_model, filtering_predicate),\n",
    "          ]\n",
    "\n",
    "# maps model names to indices over <models> array\n",
    "model_names = {name: i for i, name in enumerate(\n",
    "    ['Naive KMeans', 'Bayes', 'KNN', 'Random Forest', 'Gradient Boosting', 'MLP', 'MLP_bigger', 'PCA_SVM', 'PCA_MLP', 'Keras_NN', \"Transfer_model\", \"1D_CNN\"])}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash_bootstrap_components as dbc\n",
    "import plotly.express as px\n",
    "import json\n",
    "from dash import html, dcc, no_update, ctx\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import Input, Output\n",
    "from dash.exceptions import PreventUpdate\n",
    "\n",
    "# our modules you can modify\n",
    "import libs_tools.dash.custom_components as cc\n",
    "from libs_tools.visualization import plot_spectra, plot_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = JupyterDash(__name__, external_stylesheets=[dbc.themes.FLATLY])\n",
    "app.title = 'LIBS Segmentation'\n",
    "\n",
    "mean_spectrum = X.mean(axis=(0, 1))\n",
    "\n",
    "# short text-based exaplanation of the app\n",
    "introduction = dbc.Card([\n",
    "    dbc.CardHeader('Introduction'),\n",
    "    dbc.CardBody('Introduction goes here'),\n",
    "])\n",
    "\n",
    "# hyperspectral image, along with the drawing panel\n",
    "image_panel = dbc.Card([\n",
    "    dbc.CardHeader('Image panel'),\n",
    "    dbc.CardBody([\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody(dbc.RadioItems(\n",
    "                        id=\"mode_button\",\n",
    "                        className=\"btn-group\",\n",
    "                        inputClassName=\"btn-check\",\n",
    "                        labelClassName=\"btn btn-outline-primary\",\n",
    "                        labelCheckedClassName=\"active\",\n",
    "                        options=[\n",
    "                            {\"label\": \"Reset\", \"value\": -4},  # TODO reset should be seperate button (not be a mode)\n",
    "                            {\"label\": \"Zoom\", \"value\": -3},\n",
    "                            {\"label\": \"Clear\", \"value\": -1},\n",
    "                             {\"label\": \"Ignore\", \"value\": -2}, ] + [\n",
    "                            {'label': f'Class {i}', 'value': i} for i in range(NUM_CLASSES)\n",
    "                        ],\n",
    "                        value=0\n",
    "                    )),\n",
    "                ]),\n",
    "            ]),\n",
    "\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody(dcc.Input(\n",
    "                        id='width',\n",
    "                        type='number',\n",
    "                        placeholder='Brush width (2)'\n",
    "                    )),\n",
    "                ]),\n",
    "            ]),\n",
    "        ]),\n",
    "        dbc.Row([\n",
    "            dbc.Card(dbc.CardBody(dcc.Graph(\n",
    "                id='x_map',\n",
    "                config={\n",
    "                    'displayModeBar': False\n",
    "                },\n",
    "            ))),\n",
    "        ])\n",
    "    ])\n",
    "])\n",
    "\n",
    "if app_mode == 0:\n",
    "# saving and loading past work, themes?, colorscales?\n",
    "    application_panel = dbc.Card([\n",
    "        dbc.CardHeader('Application panel'),\n",
    "            dbc.Row([\n",
    "                dbc.Col([dbc.Button('Download Manual Labels', id='save_labels')]),\n",
    "                dbc.Col(dcc.Upload(dbc.Button('Upload Manual Labels'),id='load_labels')),\n",
    "                dbc.Col(dbc.Button('Download Segmentation', id='save_output')),\n",
    "            ]),\n",
    "    ])\n",
    "else:\n",
    "    application_panel = dbc.Card([\n",
    "        dbc.CardHeader('Application panel'),\n",
    "            dbc.Row([\n",
    "                dbc.Col([dbc.Button('Download Manual Labels', id='save_labels')]),\n",
    "                dbc.Col(dcc.Upload(dbc.Button('Upload Manual Labels'),id='load_labels')),\n",
    "                dbc.Col(dbc.Button('Download Segmentation', id='save_output')),\n",
    "            ]),\n",
    "            html.Br(),\n",
    "            dbc.Row([\n",
    "                dbc.Card(dbc.CardBody(html.Div('Accuracy: ', id='acc')))\n",
    "            ]),\n",
    "    ])\n",
    "\n",
    "options = [{'label': name, 'value': val} for name, val in model_names.items()]\n",
    "# controls the segmentation model and the output display\n",
    "model_panel = dbc.Card([\n",
    "    dbc.CardHeader('Model panel'),\n",
    "    dbc.Row([\n",
    "        dbc.Col([dbc.RadioItems(\n",
    "            id=\"show_output_btn\",\n",
    "            className=\"btn-group\",\n",
    "            inputClassName=\"btn-check\",\n",
    "            labelClassName=\"btn btn-outline-primary\",\n",
    "            labelCheckedClassName=\"active\",\n",
    "            options=[\n",
    "                {\"label\": \"Show Segmentation\", \"value\": 0},\n",
    "                {\"label\": \"Show Labels\", \"value\": 1},\n",
    "                {\"label\": \"Show Spectra\", \"value\": 2},\n",
    "            ],\n",
    "            value=2\n",
    "        )]) if app_mode > 0 else dbc.Col([dbc.Button('Show Segmentation', id='show_output_btn', disabled=True)]),\n",
    "        dbc.Col([dbc.Button('Train Model', id='retrain_btn')]),\n",
    "        dbc.Col([dbc.Select(\n",
    "            id='model_identifier',\n",
    "            placeholder=options[0]['label'],\n",
    "            options=options,\n",
    "        )])\n",
    "    ])\n",
    "])\n",
    "\n",
    "# currently hovered on spectrum, TODO add support for clicking\n",
    "selected_spectra = dbc.Card([\n",
    "    dbc.CardHeader('Currently selected spectrum'),\n",
    "    dbc.CardBody([\n",
    "        dcc.Graph(id='point_plot'),\n",
    "    ])\n",
    "])\n",
    "\n",
    "fig = plot_spectra([mean_spectrum], calibration=calibration, colormap=RANGE_SLIDER_COLORS)\n",
    "fig.update_layout(\n",
    "    template='plotly_white',\n",
    "    yaxis=dict(fixedrange=True,),\n",
    "    plot_bgcolor= 'rgba(0, 0, 0, 0)',\n",
    "    paper_bgcolor= 'rgba(0, 0, 0, 0)',\n",
    "    margin=dict(l=0, r=0, b=0, t=0,),\n",
    ")\n",
    "\n",
    "range_slider = dbc.Card([\n",
    "    dbc.CardHeader('Mean spectrum (resize to change how the total intensity is calculated)'),\n",
    "    dbc.CardBody([\n",
    "        dcc.Graph(id='range_slider', figure=fig),\n",
    "    ])\n",
    "])\n",
    "\n",
    "meta = html.Div(\n",
    "    [\n",
    "        dcc.Store(id='manual_labels', data=np.zeros((DIM)) - 1), # TODO storage type? currently loses data on reload\n",
    "        dcc.Store(id='model_output', data=None), # TODO storage type? currently loses data on reload\n",
    "        html.Div(id='test'),\n",
    "        dcc.Location(id='url'),\n",
    "        html.Div(id='screen_resolution', style={'display': 'none'}),\n",
    "        dcc.Download(id='download'),\n",
    "    ],\n",
    "    # TODO style = no-display\n",
    ")\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dbc.Container([\n",
    "        dbc.Row([\n",
    "            dbc.Col(introduction),\n",
    "        ], justify='evenly'),\n",
    "        html.Br(),\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Row([\n",
    "                    dbc.Col(image_panel)\n",
    "                ]),\n",
    "                html.Br(),\n",
    "                dbc.Row([\n",
    "                    application_panel\n",
    "                ])\n",
    "            ], width=7),\n",
    "            dbc.Col([\n",
    "                dbc.Row([\n",
    "                    model_panel\n",
    "                ]),\n",
    "                html.Br(),\n",
    "                dbc.Row([\n",
    "                    selected_spectra\n",
    "                ]),\n",
    "                html.Br(),\n",
    "                dbc.Row([\n",
    "                    range_slider\n",
    "                ]),\n",
    "            ], width=4)\n",
    "        ], justify=\"evenly\",),\n",
    "        dbc.Row([\n",
    "            dbc.Col([meta])\n",
    "        ])\n",
    "    ], fluid=True)\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mouse_path_to_indices(path):\n",
    "    indices_str = [\n",
    "        el.replace(\"M\", \"\").replace(\"Z\", \"\").split(\",\") for el in path.split(\"L\")\n",
    "    ]\n",
    "    return list(map(tuple, np.rint(np.array(indices_str, dtype=float)).astype(int).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from matplotlib import cm\n",
    "from base64 import b64decode\n",
    "import io\n",
    "\n",
    "# get screen resolution (to manually resize the hyperspectral image)\n",
    "app.clientside_callback(\n",
    "    \"\"\"\n",
    "    function(href) {\n",
    "        var w = window.innerWidth;\n",
    "        var h = window.innerHeight;\n",
    "        return JSON.stringify({'height': h, 'width': w});\n",
    "    }\n",
    "    \"\"\",\n",
    "    Output('screen_resolution', 'children'),\n",
    "    Input('url', 'href')\n",
    ")\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('manual_labels', 'data'),\n",
    "    Input('manual_labels', 'data'),\n",
    "    Input('mode_button', 'value'),\n",
    "    Input('width', 'value'),\n",
    "    Input('x_map', 'relayoutData'),\n",
    "    prevent_initial_call=True,\n",
    ")\n",
    "def update_manual_labels(memory, mode, width, relayout):\n",
    "    if mode == -4:\n",
    "        return np.zeros(DIM) - 1\n",
    "    if ctx.triggered_id != 'x_map' or 'shapes' not in relayout or mode < -2:\n",
    "        raise PreventUpdate\n",
    "    img = Image.fromarray(np.array(memory))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    node_coords = mouse_path_to_indices(relayout['shapes'][-1]['path'])\n",
    "    # TODO bug leaves little holes\n",
    "    draw.line(node_coords, fill=mode, width=int(width) if width else 2, joint='curve')\n",
    "    return np.asarray(img)\n",
    "\n",
    "\n",
    "# TODO delete\n",
    "@app.callback(\n",
    "    Output('test', 'children'),\n",
    "    Input('load_labels', 'contents'),\n",
    ")\n",
    "def idk(inp):\n",
    "    return ''\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('retrain_btn', 'outline'),\n",
    "    Input('retrain_btn', 'n_clicks'),\n",
    "    Input('manual_labels', 'data'),\n",
    "    Input('model_identifier', 'value'),\n",
    "    prevent_initial_call=True,\n",
    ")\n",
    "def highlight_retrain_btn(*args, **kwargs):\n",
    "    if ctx.triggered_id == 'retrain_btn':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('download', 'data'),\n",
    "    Input('save_labels', 'n_clicks'),\n",
    "    Input('save_output', 'n_clicks'),\n",
    "    Input('manual_labels', 'data'),\n",
    "    Input('model_output', 'data'),\n",
    "    prevent_initial_call=True,\n",
    ")\n",
    "def download_files(l_click, s_click, manual_labels, model_out):\n",
    "    if ctx.triggered_id == 'save_labels':\n",
    "        return {'content': json.dumps(manual_labels), 'filename':'manual_labels.json'}\n",
    "    elif ctx.triggered_id == 'save_output':\n",
    "        return {'content': json.dumps(model_out), 'filename':'segmentation_mask.json'}\n",
    "    raise PreventUpdate\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('manual_labels', 'data', allow_duplicate=True),\n",
    "    Input('load_labels', 'contents'),\n",
    "    prevent_initial_call=True,\n",
    ")\n",
    "def upload_labels(upload):\n",
    "    content_type, content_string = upload.split(\",\")\n",
    "    decoded = b64decode(content_string)\n",
    "    return json.loads(io.BytesIO(decoded).getvalue())\n",
    "\n",
    "if app_mode == 0:\n",
    "    @app.callback(\n",
    "        Output('show_output_btn', 'disabled'),\n",
    "        Input('retrain_btn', 'n_clicks'),\n",
    "        prevent_initial_call=True,\n",
    "    )\n",
    "    def disable_show_segmentation(click):\n",
    "        if click is not None:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('model_output', 'data'),\n",
    "    Input('retrain_btn', 'n_clicks'),\n",
    "    Input('manual_labels', 'data'),\n",
    "    Input('model_identifier', 'value'),\n",
    ")\n",
    "def calculate_model_output(_, labels, model_identifier):\n",
    "    if ctx.triggered_id != 'retrain_btn':\n",
    "        raise PreventUpdate\n",
    "    \n",
    "    model_identifier = int(model_identifier) if model_identifier else 0\n",
    "\n",
    "    y_in = np.array(labels).flatten()\n",
    "\n",
    "    # TODO wrapper here\n",
    "    # X_in 4900, 3700\n",
    "    # y_in labels, -1 unknown\n",
    "    # check pairs corresponding to each other\n",
    "    return models[int(model_identifier)].fit(X_in, y_in).predict(X_in).reshape(DIM)\n",
    "\n",
    "\n",
    "if app_mode > 0:\n",
    "    from itertools import permutations\n",
    "    @app.callback(\n",
    "        Output('acc', 'children'),\n",
    "        Input('model_output', 'data'),\n",
    "        prevent_initial_call=True,\n",
    "    )\n",
    "    def display_acc(y):\n",
    "        y = np.array(y)\n",
    "        new_y = np.zeros(y.shape)\n",
    "        scores = []\n",
    "        for label0, label1, label2 in permutations((0, 1, 2)):\n",
    "            new_y[y == 0] = label0\n",
    "            new_y[y == 1] = label1\n",
    "            new_y[y == 2] = label2\n",
    "            scores.append(np.sum((new_y == y_true) & (y_true != -2)) / np.sum((y_true != -2)))\n",
    "        return f'Accuracy: {max(scores)}'\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('x_map', 'figure'),\n",
    "    Input('range_slider', 'relayoutData'),\n",
    "    Input('manual_labels', 'data'),\n",
    "    Input('screen_resolution', 'children'),\n",
    "    Input('mode_button', 'value'),\n",
    "    Input('show_output_btn', 'value' if app_mode > 0 else 'n_clicks'),\n",
    "    Input('model_output', 'data'),\n",
    ")\n",
    "def update_X_map(wave_range, manual_labels, screen_resolution, mode, show_segment_btn, y):\n",
    "    # unpack input values\n",
    "    manual_labels = np.array(manual_labels)\n",
    "    screen_resolution = json.loads(screen_resolution)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # broadcast manual labels to multi-channel image\n",
    "    mask = np.repeat(manual_labels[:,:, np.newaxis], 4, axis=2)\n",
    "\n",
    "    # choose one of two main modes\n",
    "    if (app_mode > 0 and show_segment_btn == 2) or (not app_mode > 0 and (show_segment_btn is None or show_segment_btn % 2 == 0)):\n",
    "        # show image\n",
    "        if wave_range is None or \"xaxis.autorange\" in wave_range or 'autosize' in wave_range:\n",
    "            values = X.sum(axis=2)\n",
    "        else:\n",
    "            values = X[:, :, (calibration >= float(wave_range[\"xaxis.range[0]\"])) & (calibration <= float(wave_range[\"xaxis.range[1]\"]))].sum(axis=2)\n",
    "        img = np.where(mask >= 0, cm.Set1(manual_labels / (NUM_CLASSES), alpha=1.) * 255, cm.Reds((values - values.min()) / values.max(), alpha=1.) * 255)\n",
    "    elif (app_mode > 0 and show_segment_btn == 0) or not app_mode > 0:\n",
    "        # show segmentation\n",
    "        img = np.where(mask >= 0, cm.Set1(manual_labels / (NUM_CLASSES), alpha=1.) * 255, cm.Set1(y / (NUM_CLASSES), alpha=.8) * 255)\n",
    "    else:\n",
    "        img = cm.Set1(y_true / (NUM_CLASSES), alpha=1) * 255\n",
    "        img[y_true == -2, :] = (128, 128, 128, 255)\n",
    "\n",
    "    img = np.where(mask == -2, 128, img)\n",
    "\n",
    "    # generate plot\n",
    "    fig = px.imshow(img=img, labels={})\n",
    "    fig.update_traces(\n",
    "        hovertemplate='<',\n",
    "        hoverinfo='skip',\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        template='plotly_white',\n",
    "        plot_bgcolor= 'rgba(0, 0, 0, 0)',\n",
    "        paper_bgcolor= 'rgba(0, 0, 0, 0)',\n",
    "        margin=dict(l=0, r=0, b=0, t=0, pad=0),\n",
    "        dragmode='zoom' if mode < -2 else 'drawopenpath',\n",
    "        newshape=dict(opacity=0),  # TODO shapes are currently just hidden but not deleted\n",
    "        xaxis=dict(visible=False, range=fig['layout']['xaxis']['range'] if fig else None),\n",
    "        yaxis=dict(visible=False, range=fig['layout']['yaxis']['range'] if fig else None),\n",
    "        width=int(min(screen_resolution['height'] * .9, screen_resolution['width'] * .7)),\n",
    "        height=int(min(screen_resolution['height'] * .9, screen_resolution['width'] * .7)),\n",
    "        uirevision='None',\n",
    "        shapes=[],  # TODO this does not remove the shapes!\n",
    "    )\n",
    "    fig.update_shapes(editable=False)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('point_plot', 'figure'),\n",
    "    Input('x_map', 'hoverData'),\n",
    ")\n",
    "def update_point_plot(hover):\n",
    "    if hover is not None:\n",
    "        x, y = hover['points'][0]['x'], hover['points'][0]['y']\n",
    "    else:\n",
    "        x, y = 0, 0\n",
    "    fig = plot_spectra([mean_spectrum, X[x, y, :]], calibration=calibration, labels=['mean', 'hover'])\n",
    "    fig.update_layout(\n",
    "        template='plotly_white',\n",
    "        plot_bgcolor= 'rgba(0, 0, 0, 0)',\n",
    "        paper_bgcolor= 'rgba(0, 0, 0, 0)',\n",
    "        margin=dict(l=0, r=0, b=0, t=0,),\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc159360cd010ded565e554558753114b72891f332c975d5de22c541081208b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
